# -*- coding: utf-8 -*-
"""direct_regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17laeZyoqHkRxZAwLQqz9Ei7yarlo8OKw
"""

from __future__ import print_function
from __future__ import division
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import torchvision
from torchvision import datasets, models, transforms
import matplotlib.pyplot as plt
import time
import os
import copy
import glob
from torch.utils.data import Dataset, DataLoader
from PIL import Image
from skimage.draw import polygon
import torch.nn.functional as F
print("PyTorch Version: ",torch.__version__)
print("Torchvision Version: ",torchvision.__version__)

from google.colab import drive
drive.mount('/content/drive')

"""Hyperparameters"""

# Top level data directory. Here we assume the format of the directory conforms
#   to the ImageFolder structure
data_dir = "/content/drive/My Drive/cornell_grasps/"

# Regressor output size
num_classes = 6

# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]
model_name = "alexnet"

# Batch size for training (change depending on how much memory you have)
batch_size = 128

# Number of epochs to train for
num_epochs = 20

# Flag for feature extracting. When False, we finetune the whole model,
#   when True we only update the reshaped layer params
feature_extract = True

# validation split
split = 0.9

"""Train helper functions"""

# convert rgb and depth images to three-channel rg-d image
def rgb_to_rgd(img_rgb, img_d, transforms):
    img_rgd_t = transforms['val'](img_rgb)
    img_d_t = transforms['depth'](img_d)
    img_d_t = np.clip((img_d_t - img_d_t.mean()), -1, 1)
    img_rgd_t[2] = img_d_t
    return img_rgd_t

# for a file with N grasp rectangles, returns a Nx4x2 array of the coordinates
def get_grasp_rectangles(file_name):
    with open(file_name, 'r') as f:
        coords = list(map(lambda coordinate: float(coordinate), f.read().strip().split()))
    rectangles = []
    i = 0
    while i < len(coords):
        rectangle = np.array([[coords[i], coords[i+1]],
                               [coords[i+2], coords[i+3]],
                               [coords[i+4], coords[i+5]],
                               [coords[i+6], coords[i+7]]])
        if not np.isnan(rectangle).any():
            rectangles.append(rectangle)
        i += 8
    return np.array(rectangles)

# converts a grasp box to the 6-parameter grasp coordinates
def box_to_grasp(box):
    x = (box[0,0] + (box[2,0] - box[0,0])/2)/100
    y = (box[0,1] + (box[2,1] - box[0,1])/2)/100
    theta = np.arctan2(box[1,1] - box[0,1], box[1,0] - box[0,0])
    h = ((box[3,0]-box[0,0])**2 + (box[3,1]-box[0,1])**2)**0.5/100
    w = ((box[1,0]-box[0,0])**2 + (box[1,1]-box[0,1])**2)**0.5/100
    return np.array([x, y, h, w, np.sin(2*theta), np.cos(2*theta)])

# converts 6-parameter grasp coordinates to a grasp box
def grasp_to_box(grasp):
    x, y, h, w, sin, cos = grasp
    x, y, h, w = 100*x, 100*y, 100*h, 100*w
    theta = np.arctan2(sin, cos)/2
    edge1 = [x -w/2*np.cos(theta) +h/2*np.sin(theta), y -w/2*np.sin(theta) -h/2*np.cos(theta)]
    edge2 = [x +w/2*np.cos(theta) +h/2*np.sin(theta), y +w/2*np.sin(theta) -h/2*np.cos(theta)]
    edge3 = [x +w/2*np.cos(theta) -h/2*np.sin(theta), y +w/2*np.sin(theta) +h/2*np.cos(theta)]
    edge4 = [x -w/2*np.cos(theta) -h/2*np.sin(theta), y -w/2*np.sin(theta) +h/2*np.cos(theta)]
    return np.array([edge1, edge2, edge3, edge4])

# gets angle of a grasp box
def box_angle(box):
    return np.arctan2(box[1,0] - box[0,0], box[1,1] - box[0,1])

# calculate rectangle metric between two rectangles
def rectangle_metric(rect1, rect2, angle_threshold = np.pi/6):
    ang1 = box_angle(rect1)
    ang2 = box_angle(rect2)
    if abs((ang1 - ang2 + np.pi/2) % np.pi - np.pi/2) > angle_threshold:
        return 0
    rr1, cc1 = polygon(rect1[:, 0], rect1[:, 1])
    rr2, cc2 = polygon(rect2[:, 0], rect2[:, 1])

    try:
        r_max = max(rr1.max(), rr2.max()) + 1
        c_max = max(cc1.max(), cc2.max()) + 1
    except:
        print("exception")
        return 0

    canvas = np.zeros((r_max, c_max))
    canvas[rr1, cc1] += 1
    canvas[rr2, cc2] += 1
    union = np.sum(canvas > 0)
    if union == 0:
        print("union")
        return 0
    intersection = np.sum(canvas == 2)
    return intersection/union

# calculate maximum rectangle metric between pred_rec and rects
def max_rect_metric(pred_rec, rects):
    max_metric = 0
    for rec in rects:
        max_metric = max(max_metric, rectangle_metric(pred_rec, rec))
    return max_metric

# not being used
def custom_loss(pred_grasp, true_grasp):
    x1, y1, h1, w1, sin1, cos1 = pred_grasp[:,0], pred_grasp[:,1], pred_grasp[:,2], pred_grasp[:,3], pred_grasp[:,4], pred_grasp[:,5]
    x2, y2, h2, w2, sin2, cos2 = true_grasp[:,0], true_grasp[:,1], true_grasp[:,2], true_grasp[:,3], true_grasp[:,4], true_grasp[:,5]
    print("x1", x1)
    print("x2", x2)
    x_loss = F.mse_loss(x1/500, x2/500)
    y_loss = F.mse_loss(y1/500, y2/500)
    h_loss = F.mse_loss(h1/500, h2/500)
    w_loss = F.mse_loss(w1/500, w2/500)
    sin_loss = F.mse_loss(sin1, sin2)
    cos_loss = F.mse_loss(cos1, cos2)
    return x_loss + y_loss + h_loss + w_loss + sin_loss + cos_loss

class GraspDataset(Dataset):
    """Grasp dataset."""

    def __init__(self, file_path, transforms, start=0.0, end=1.0, ds_rotate=0, **kwargs):
        """
        :param file_path: Cornell Dataset directory.
        :param start: If splitting the dataset, start at this fraction [0,1]
        :param end: If splitting the dataset, finish at this fraction
        :param ds_rotate: If splitting the dataset, rotate the list of items by this fraction first
        :param kwargs: kwargs for GraspDatasetBase
        """
        graspf = glob.glob(os.path.join(file_path, '*', 'pcd*cpos.txt'))
        graspf.sort()
        l = len(graspf)
        if l == 0:
            raise FileNotFoundError('No dataset files found. Check path: {}'.format(file_path))

        if ds_rotate:
            graspf = graspf[int(l*ds_rotate):] + graspf[:int(l*ds_rotate)]

        depthf = [f.replace('cpos.txt', 'd.tiff') for f in graspf]
        rgbf = [f.replace('d.tiff', 'r.png') for f in depthf]

        self.transforms = transforms
        self.grasp_files = graspf[int(l*start):int(l*end)]
        self.depth_files = depthf[int(l*start):int(l*end)]
        self.rgb_files = rgbf[int(l*start):int(l*end)]

    def __len__(self):
        return len(self.grasp_files)

    def __getitem__(self, idx):
        img_rgb = Image.open(self.rgb_files[idx])
        img_d = Image.open(self.depth_files[idx])
        img_rgd = rgb_to_rgd(img_rgb, img_d, self.transforms)

        rectangles = get_grasp_rectangles(self.grasp_files[idx])

        r_idx = np.random.randint(len(rectangles))
        rectangle = rectangles[r_idx]
        single_grasp = box_to_grasp(rectangle)

        return idx, img_rgd, torch.from_numpy(single_grasp).float()
    def get_rectangles(self, idx):
        return get_grasp_rectangles(self.grasp_files[idx])

"""Train function"""

def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):
    since = time.time()

    val_acc_history = []

    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = 0.0

    for epoch in range(num_epochs):
        print('Epoch {}/{}'.format(epoch, num_epochs - 1))
        print('-' * 10)

        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode

            running_loss = 0.0
            running_corrects = 0

            # Iterate over data.
            for idx, inputs, labels in dataloaders[phase]:
                # inputs = inputs.to(device)
                # labels = labels.to(device)

                # zero the parameter gradients
                optimizer.zero_grad()


                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    # Get model outputs and calculate loss
                    outputs = model(inputs)

                    loss = criterion(outputs, labels)
                    print("loss", loss)

                    # _, preds = torch.max(outputs, 1)

                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()


                if phase == 'val':
                    rectangles = dataloaders[phase].dataset.get_rectangles(idx)
                    pred_boxes = grasp_to_box(outputs[0])

                    running_corrects += np.sum(max_rect_metric(pred_boxes, rectangles) > 0.25)

                # statistics
                running_loss += loss.item() * inputs.size(0)
                # running_corrects += torch.sum(preds == labels.data)
                

            epoch_loss = running_loss / len(dataloaders[phase].dataset)
            epoch_acc = 0
            if phase == 'val':
                epoch_acc = running_corrects / len(dataloaders[phase].dataset)


            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))

            # deep copy the model
            if phase == 'val' and epoch_acc > best_acc:
                best_acc = epoch_acc
                best_model_wts = copy.deepcopy(model.state_dict())
            if phase == 'val':
                val_acc_history.append(epoch_acc)

        print()

    time_elapsed = time.time() - since
    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))
    print('Best val Acc: {:4f}'.format(best_acc))

    # load best model weights
    model.load_state_dict(best_model_wts)
    return model, val_acc_history

# Helper function for modifying AlexNet
def set_parameter_requires_grad(model, feature_extracting):
    if feature_extracting:
        for param in model.parameters():
            param.requires_grad = False

"""Create model"""

def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):
    # Initialize these variables which will be set in this if statement. Each of these
    #   variables is model specific.
    model_ft = None
    input_size = 0

    if model_name == "resnet":
        """ Resnet18
        """
        model_ft = models.resnet18(pretrained=use_pretrained)
        set_parameter_requires_grad(model_ft, feature_extract)
        num_ftrs = model_ft.fc.in_features
        model_ft.fc = nn.Linear(num_ftrs, num_classes)
        input_size = 224

    elif model_name == "alexnet":
        """ Alexnet
        """
        model_ft = models.alexnet(pretrained=use_pretrained)
        set_parameter_requires_grad(model_ft, feature_extract)
        num_ftrs = model_ft.classifier[6].in_features
        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)
        input_size = 224


    else:
        print("Invalid model name, exiting...")
        exit()

    return model_ft, input_size

# Initialize the model for this run
model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)

# Print the model we just instantiated
print(model_ft)

# Create transformation functions for data
data_transforms = {
    # 'train': transforms.Compose([
    #     transforms.RandomResizedCrop(input_size),
    #     transforms.RandomHorizontalFlip(),
    #     transforms.ToTensor(),
    #     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    # ]),
    'train': transforms.Compose([
        transforms.Resize(input_size),
        transforms.CenterCrop(input_size),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(input_size),
        transforms.CenterCrop(input_size),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'depth': transforms.Compose([
        transforms.Resize(input_size),
        transforms.CenterCrop(input_size),
        transforms.ToTensor(),
    ]),
}

"""Load Datasets"""

train_dataset = GraspDataset(data_dir, data_transforms, start=0.0, end=split)
train_data = DataLoader(
    train_dataset,
    batch_size=batch_size,
    shuffle=True,
    num_workers=4
)
val_dataset = GraspDataset(data_dir, data_transforms, start=split, end=1.0)
val_data = DataLoader(
    val_dataset,
    batch_size=1,
    shuffle=False,
    num_workers=4
)
dataloaders_dict = {'train': train_data, 'val': val_data}

"""Train all or only some weights"""

# Gather the parameters to be optimized/updated in this run. If we are
#  finetuning we will be updating all parameters. However, if we are
#  doing feature extract method, we will only update the parameters
#  that we have just initialized, i.e. the parameters with requires_grad
#  is True.
params_to_update = model_ft.parameters()
print("Params to learn:")
# feature_extract = False
if feature_extract:
    params_to_update = []
    for name,param in model_ft.named_parameters():
        if param.requires_grad == True:
            params_to_update.append(param)
            print("\t",name)
else:
    for param in model_ft.parameters():
        param.requires_grad = True
    for name,param in model_ft.named_parameters():
        if param.requires_grad == True:
            print("\t",name)

# Observe that all parameters are being optimized
optimizer_ft = optim.SGD(params_to_update, lr=0.0005, momentum=0.9, weight_decay=0.001)

# Setup the loss fxn
criterion = nn.MSELoss()

# Train and evaluate
model_ft, hist1 = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs)

# Train all weights in the network to fine-tune results
params_to_update = model_ft.parameters()
print("Params to learn:")
feature_extract = False
if feature_extract:
    params_to_update = []
    for name,param in model_ft.named_parameters():
        if param.requires_grad == True:
            params_to_update.append(param)
            print("\t",name)
else:
    for param in model_ft.parameters():
        param.requires_grad = True
    for name,param in model_ft.named_parameters():
        if param.requires_grad == True:
            print("\t",name)

# Observe that all parameters are being optimized
optimizer_ft = optim.SGD(params_to_update, lr=0.0005, momentum=0.9, weight_decay=0.001)

# Setup the loss fxn
criterion = nn.MSELoss()

# Train and evaluate
model_ft, hist2 = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs)

"""Create Accuracy Plots"""

plt.plot(hist1+hist2)
# plt.plot(hist2)
plt.title("Validation Accuracy per Epoch")
plt.ylabel("accuracy")
plt.xlabel("epoch")
# plt.show()
plt.savefig("model_1_accuracy.png")

"""Test the trained model"""

i = 26
x1, x2, x3 = train_dataset.__getitem__(i)
plt.imshow(x2.squeeze().permute(1,2,0))

with torch.no_grad():
    pred_grasp = model_ft(x2.unsqueeze(0))
    print(pred_grasp)
    pred_box = grasp_to_box(pred_grasp.squeeze())

given_recs = train_dataset.get_rectangles(i)

img = Image.open(train_dataset.rgb_files[i])
plt.imshow(img)
x = pred_box[:,0]
y = pred_box[:,1]

for rec in given_recs:
    xs = rec[:,0]
    ys = rec[:,1]
    plt.plot(xs[:2],ys[:2], 'b', linewidth=1)
    plt.plot(xs[2:],ys[2:], 'b', linewidth=1)
    plt.plot(xs[1:3],ys[1:3], 'r', linewidth=1)
    plt.plot([xs[0],xs[3]],[ys[0],ys[3]], 'r', linewidth=1)
plt.plot(x[:2],y[:2], 'g', linewidth=3)
plt.plot(x[2:],y[2:], 'g', linewidth=3)
plt.plot(x[1:3],y[1:3], 'y', linewidth=3)
plt.plot([x[0],x[3]],[y[0],y[3]], 'y', linewidth=3)

plt.savefig('grasp6_labels.png')

img_rgb = Image.open("pcd0144r.png")
img_d = Image.open("pcd0144d.tiff")
img_rgd = rgb_to_rgd(img_rgb, img_d, data_transforms)

with torch.no_grad():
    pred_grasp = model_ft(img_rgd.unsqueeze(0))
    print(pred_grasp)
    pred_box = grasp_to_box(pred_grasp.squeeze())

img2 = Image.open("pcd0144r.png")
plt.imshow(img2, aspect='auto')
# plt.scatter(pred_box[:,0], pred_box[:,1])
x = pred_box[:,0]
y = pred_box[:,1]
plt.plot(x[:2],y[:2], 'g', linewidth=3)
plt.plot(x[2:],y[2:], 'g', linewidth=3)
plt.plot(x[1:3],y[1:3], 'y', linewidth=3)
plt.plot([x[0],x[3]],[y[0],y[3]], 'y', linewidth=3)
plt.savefig('test.png')